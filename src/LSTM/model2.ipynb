{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " sequence_input (InputLayer)    [(None, 1000)]       0           []                               \n",
      "                                                                                                  \n",
      " embedding_11 (Embedding)       (None, 1000, 128)    640000      ['sequence_input[0][0]']         \n",
      "                                                                                                  \n",
      " lstm_21 (LSTM)                 (None, 64)           49408       ['embedding_11[0][0]']           \n",
      "                                                                                                  \n",
      " other_input (InputLayer)       [(None, 10)]         0           []                               \n",
      "                                                                                                  \n",
      " dropout_11 (Dropout)           (None, 64)           0           ['lstm_21[0][0]']                \n",
      "                                                                                                  \n",
      " dense_20 (Dense)               (None, 32)           352         ['other_input[0][0]']            \n",
      "                                                                                                  \n",
      " concatenate_11 (Concatenate)   (None, 96)           0           ['dropout_11[0][0]',             \n",
      "                                                                  'dense_20[0][0]']               \n",
      "                                                                                                  \n",
      " dense_21 (Dense)               (None, 5)            485         ['concatenate_11[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 690,245\n",
      "Trainable params: 690,245\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "X_train_sequences shape: (13731, 1000)\n",
      "X_train_other_features shape: (13731, 10)\n",
      "y_train_sequences shape: (13731,)\n",
      "Epoch 1/10\n",
      "215/215 [==============================] - 156s 710ms/step - loss: 1.6137 - accuracy: 0.2001 - val_loss: 1.6118 - val_accuracy: 0.2075\n",
      "Epoch 2/10\n",
      "215/215 [==============================] - 140s 653ms/step - loss: 1.5326 - accuracy: 0.3413 - val_loss: 1.6933 - val_accuracy: 0.1870\n",
      "Epoch 3/10\n",
      "215/215 [==============================] - 142s 660ms/step - loss: 1.2220 - accuracy: 0.5231 - val_loss: 1.9342 - val_accuracy: 0.2030\n",
      "Epoch 4/10\n",
      "215/215 [==============================] - 143s 663ms/step - loss: 0.8695 - accuracy: 0.6883 - val_loss: 2.3531 - val_accuracy: 0.1985\n",
      "Epoch 5/10\n",
      "215/215 [==============================] - 143s 665ms/step - loss: 0.5727 - accuracy: 0.8073 - val_loss: 2.9857 - val_accuracy: 0.1995\n",
      "Epoch 6/10\n",
      "215/215 [==============================] - 143s 664ms/step - loss: 0.3496 - accuracy: 0.8877 - val_loss: 3.6337 - val_accuracy: 0.2015\n",
      "Epoch 7/10\n",
      "215/215 [==============================] - 142s 661ms/step - loss: 0.2112 - accuracy: 0.9355 - val_loss: 4.3323 - val_accuracy: 0.2020\n",
      "Epoch 8/10\n",
      "215/215 [==============================] - 143s 665ms/step - loss: 0.1303 - accuracy: 0.9610 - val_loss: 4.8828 - val_accuracy: 0.1965\n",
      "Epoch 9/10\n",
      "215/215 [==============================] - 142s 660ms/step - loss: 0.0813 - accuracy: 0.9787 - val_loss: 5.5743 - val_accuracy: 0.1970\n",
      "Epoch 10/10\n",
      "215/215 [==============================] - 142s 662ms/step - loss: 0.0543 - accuracy: 0.9858 - val_loss: 5.9522 - val_accuracy: 0.1985\n",
      "63/63 [==============================] - 5s 86ms/step - loss: 5.9522 - accuracy: 0.1985\n",
      "Test Accuracy: 0.1985\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Input, Concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from logger import logging\n",
    "from exception import CustomException \n",
    "\n",
    "# -------------------------------\n",
    "# Hyperparameters\n",
    "# -------------------------------\n",
    "VOCAB_SIZE = 5000\n",
    "SEQ_LEN = 1000\n",
    "EMBED_DIM = 128\n",
    "LSTM_DIM = 64\n",
    "NUM_LAYERS = 2\n",
    "LR = 1e-3\n",
    "\n",
    "# -------------------------------\n",
    "# Sample Dataset (Modify as needed)\n",
    "# -------------------------------\n",
    "X_train_sequences = np.random.randint(1, VOCAB_SIZE, (13731, SEQ_LEN))\n",
    "X_test_sequences = np.random.randint(1, VOCAB_SIZE, (2000, SEQ_LEN))\n",
    "X_train_other_features = np.random.rand(13731, 10)  # 10 additional features\n",
    "X_test_other_features = np.random.rand(2000, 10)\n",
    "\n",
    "y_train_sequences = np.random.randint(0, 5, (13731, 1))  # Labels between 0-4\n",
    "y_test_sequences = np.random.randint(0, 5, (2000, 1))\n",
    "\n",
    "# -------------------------------\n",
    "# Fix: Ensure Labels are Correctly Shaped\n",
    "# -------------------------------\n",
    "y_train_sequences = y_train_sequences.reshape(-1)  # (13731,)\n",
    "y_test_sequences = y_test_sequences.reshape(-1)  # (2000,)\n",
    "\n",
    "# -------------------------------\n",
    "# Define the Model\n",
    "# -------------------------------\n",
    "try:\n",
    "    def build_model(vocab_size, seq_len, embed_dim, lstm_dim, num_layers, lr):\n",
    "        # Text Input (Sequences)\n",
    "        sequence_input = Input(shape=(seq_len,), name=\"sequence_input\")\n",
    "        embedding = Embedding(vocab_size, embed_dim, mask_zero=True)(sequence_input)\n",
    "        x = LSTM(lstm_dim, return_sequences=False)(embedding)\n",
    "        x = Dropout(0.3)(x)\n",
    "        \n",
    "        # Other Features Input\n",
    "        other_input = Input(shape=(10,), name=\"other_input\")\n",
    "        other_dense = Dense(32, activation=\"relu\")(other_input)\n",
    "\n",
    "        # Merge both inputs\n",
    "        concatenated = Concatenate()([x, other_dense])\n",
    "        output = Dense(5, activation=\"softmax\")(concatenated)  # 5 classes\n",
    "\n",
    "        # Create Model\n",
    "        model = Model(inputs=[sequence_input, other_input], outputs=output)\n",
    "        model.compile(optimizer=Adam(learning_rate=lr), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "        return model\n",
    "\n",
    "    # -------------------------------\n",
    "    # Build and Train the Model\n",
    "    # -------------------------------\n",
    "    model = build_model(VOCAB_SIZE, SEQ_LEN, EMBED_DIM, LSTM_DIM, NUM_LAYERS, LR)\n",
    "    model.summary()\n",
    "\n",
    "    print(\"X_train_sequences shape:\", X_train_sequences.shape)\n",
    "    print(\"X_train_other_features shape:\", X_train_other_features.shape)\n",
    "    print(\"y_train_sequences shape:\", y_train_sequences.shape)\n",
    "\n",
    "    # Train Model\n",
    "    history = model.fit(\n",
    "        [X_train_sequences, X_train_other_features], \n",
    "        y_train_sequences,\n",
    "        validation_data=([X_test_sequences, X_test_other_features], y_test_sequences),\n",
    "        epochs=10,\n",
    "        batch_size=64\n",
    "    )\n",
    "\n",
    "    # Evaluate Model\n",
    "    test_loss, test_accuracy = model.evaluate([X_test_sequences, X_test_other_features], y_test_sequences)\n",
    "    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    raise CustomException(e, sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as lstm_model.h5\n"
     ]
    }
   ],
   "source": [
    "# Save the entire model\n",
    "model.save(\"lstm_model.h5\")\n",
    "print(\"Model saved as lstm_model.h5\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
